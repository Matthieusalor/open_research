{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Figuring out Natural Language Processing\n",
    "As I have never worked on NLP before, the purpose of this notebook was to playing arround with a dataset and trying to figure out a bunch of stuff on the subject.\n",
    "Here we will be working on the IMDB dataset which provides 50k movies text reviews and their corresponding sentiment  \"Positive\" or \"Negative\".\n",
    "\n",
    "Our job will be to find a way to learn some features that can predict the sentiment based on a textual review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "We will be getting the data from my github repositery. I have downloaded those data from Kaggle https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "orig_url='https://drive.google.com/file/d/1Tl9AMNkExM5mFw3xDuIeZ1RiDIEu4Oci/view?usp=sharing'\n",
    "file_id = orig_url.split('/')[-2]\n",
    "dwn_url='https://drive.google.com/uc?export=download&id=' + file_id\n",
    "url = requests.get(dwn_url).text\n",
    "csv_raw = StringIO(url)\n",
    "df = pd.read_csv(csv_raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Now that we have the data, and displayed some of those data, we know that there is cleaning to be made. \n",
    "\n",
    "For this analysis, I will assume that numbers are meaningless and that we need only words to predict the review. \n",
    "Therefore, we will get rid of : \n",
    "* numbers,\n",
    "* html tags,\n",
    "* uppercases,\n",
    "* any special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the other reviewers has mentioned that after watching just oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode ever saw struck me as so nasty it was surreal couldnt say was ready for it but as watched more developed taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove numbers\n",
    "df['clean_review'] = df['review'].str.replace('\\d+', '')\n",
    "# Remove any <> and everything inside\n",
    "df['clean_review'] = df['clean_review'].str.replace('<[^<]+?>', '')\n",
    "# Remove anything that is not alphanumeric\n",
    "df['clean_review'] = df['clean_review'].str.replace(r'[^A-Za-z0-9 ]+', '')\n",
    "# Remove any uppercase character\n",
    "df['clean_review'] = df['clean_review'].str.lower()\n",
    "# Remove any one character words\n",
    "df['clean_review'] = df['clean_review'].str.replace(r'\\b\\w\\b', '')\n",
    "# Remove multiple spaces \n",
    "df['clean_review'] = df['clean_review'].str.replace(r'\\s+', ' ')\n",
    "# Strip data\n",
    "df['clean_review'] = df['clean_review'].str.strip()\n",
    "\n",
    "df['clean_review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What direction ? \n",
    "Now, we have a text that seems to be way more clean. \n",
    "\n",
    "Obviously, now we will have to create some features out of all these words in order to extract the sentiment. \n",
    "What I mean by that is that we need to create a standardized framework in which any review could fit. The problem with those textual input is that they are of random sizes, and any model that we might create will need inputs of pre-defined sizes.\n",
    "\n",
    "What we will be using here is some kind of one-hot-encoding technic. The concept is simple, you take a categorical variable and transform it in vector space. ie: \n",
    "\n",
    "| category |\n",
    "|---|\n",
    "| A |\n",
    "| B |\n",
    "| C | \n",
    "\n",
    "| A | B | C |\n",
    "|---|---|---|\n",
    "| 1 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 0 | 0 | 1 |\n",
    "\n",
    "-----------\n",
    "\n",
    "Here, the columns will be some relevants words that we believe to have predictive power.\n",
    "\n",
    "In order to find them, let's play arround with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns 'words' will contains a list of all the words in the 'clean' column\n",
    "df['words'] = df.clean_review.str.split('\\s+')\n",
    "df.words[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Now we will identify ALL the words that have been used and count how many time they have been used.\n",
    "\n",
    "\n",
    "I tried to use Counter from the collection package but found it to be really slow when I was passing it entire lists so I just decided to do it in my own way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>210064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>266297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>288080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>319406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>650762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count\n",
       "is   210064\n",
       "to   266297\n",
       "of   288080\n",
       "and  319406\n",
       "the  650762"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_count = {}\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "for d in data:\n",
    "    for w in d[3]:\n",
    "        if not w in dict_count:\n",
    "            dict_count[w] = 1\n",
    "        else:\n",
    "            dict_count[w] +=1\n",
    "\n",
    "df_count = pd.DataFrame(dict_count, index=['Count']).T.sort_values('Count')\n",
    "df_count.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words problem\n",
    "And here we are, the famous stop words problems. \n",
    "This was indeed pretty well expected, the words that are the most common will be completely useless in our case. \n",
    "\n",
    "A good practice is to get rid of them.\n",
    "The sklearn library has a english stop word froze set, we will use it to do that\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>28502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>34680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>38831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>74508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>83573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count\n",
       "good   28502\n",
       "just   34680\n",
       "like   38831\n",
       "film   74508\n",
       "movie  83573"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "df_count = df_count.loc[~df_count.index.isin(stop_words.ENGLISH_STOP_WORDS)]\n",
    "df_count.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next step\n",
    "Now for each of these words, I will add a column to the DataFrame and I want to count how many time each of them appear in each review. This is where we use \"some kind\" of one-hot-encoding technics. We will not populate with 1 or 0 but with a number of occurence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_review</th>\n",
       "      <th>_predict</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>words</th>\n",
       "      <th>memories</th>\n",
       "      <th>mike</th>\n",
       "      <th>locations</th>\n",
       "      <th>learned</th>\n",
       "      <th>lovers</th>\n",
       "      <th>noticed</th>\n",
       "      <th>...</th>\n",
       "      <th>bad</th>\n",
       "      <th>great</th>\n",
       "      <th>story</th>\n",
       "      <th>really</th>\n",
       "      <th>time</th>\n",
       "      <th>good</th>\n",
       "      <th>just</th>\n",
       "      <th>like</th>\n",
       "      <th>film</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production the filming techni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought this was wonderful way to spend time o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres family where little boy jake ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love in the time of money is vi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             _review  _predict  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                        clean_review  words  memories  mike  \\\n",
       "0  one of the other reviewers has mentioned that ...      0         0     0   \n",
       "1  wonderful little production the filming techni...      0         0     0   \n",
       "2  thought this was wonderful way to spend time o...      0         0     0   \n",
       "3  basically theres family where little boy jake ...      0         0     0   \n",
       "4  petter matteis love in the time of money is vi...      0         0     0   \n",
       "\n",
       "   locations  learned  lovers  noticed  ...  bad  great  story  really  time  \\\n",
       "0          0        0       0        0  ...    0      0      0       0     0   \n",
       "1          0        0       0        0  ...    0      1      0       1     2   \n",
       "2          0        0       0        0  ...    0      1      0       0     1   \n",
       "3          0        0       0        0  ...    0      0      0       0     1   \n",
       "4          0        0       0        0  ...    0      0      0       0     2   \n",
       "\n",
       "   good  just  like  film  movie  \n",
       "0     0     3     0     0      0  \n",
       "1     0     0     0     1      0  \n",
       "2     0     0     0     0      0  \n",
       "3     0     2     1     2      3  \n",
       "4     2     0     0     2      1  \n",
       "\n",
       "[5 rows x 1503 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = df_count.tail(1500).index.tolist()\n",
    "\n",
    "# Rename the columns as their name might appear in the list of words\n",
    "df = df.rename({\n",
    "    \"sentiment\": '_predict',\n",
    "    \"review\": \"_review\"\n",
    "}, axis=1)\n",
    "\n",
    "for word in top_words:\n",
    "    df[word] = df.clean_review.str.count(word)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the interesting stuff ??\n",
    "Alright, now that we have counted everything, why don't we group our data by sentiment, positive or negative, and see if any words appears way more often in a group and not in the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wonderfully   -0.866038\n",
       "beautifully   -0.843915\n",
       "superb        -0.821084\n",
       "wonderful     -0.805434\n",
       "touching      -0.805195\n",
       "                 ...   \n",
       "poorly         8.388060\n",
       "laughable      8.653846\n",
       "waste          8.919271\n",
       "redeeming      9.017857\n",
       "worst          9.961883\n",
       "Name: diff_, Length: 1500, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df[['_predict',*top_words]].groupby('_predict').mean().T\n",
    "result['diff_'] = (result.negative / result.positive) -1\n",
    "result.diff_.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That is interesting\n",
    "So here we are, words such as beautiful and wonderful are wayyyyy more often used in a positive review than in a negative review. And words like worst, and awful are more often used in a negative review. \n",
    "\n",
    "Again, I believe those results are pretty obvious, that is just common sense. However it still took us less time than coming up with 1500 words by yourself. \n",
    "\n",
    "By looking at the data so far, I'm assuming that there should be some predictive power in our variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = df[['_predict', *result.index.to_list()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x = predict_df.drop('_predict', axis=1)\n",
    "y = predict_df['_predict']\n",
    "y = y.replace({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "total = x.shape[0]\n",
    "n = 25000\n",
    "n_test = total - n\n",
    "x_train = x.iloc[:n,:].values\n",
    "y_train = y.iloc[:n].values\n",
    "\n",
    "x_test =  x.iloc[n:,:].values\n",
    "y_test =  y.iloc[n:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the data\n",
    "Some learning models require the data to be normalize in some way. \n",
    "Here we will just standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
    "x_test_std = (x_test - x_train.mean(axis=0)) / x_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn\n",
    "It is time to create our model. \n",
    "\n",
    "This problem is a classification problem. Therefore we can choose among the following learning technics :\n",
    "\n",
    "* Linear Models\n",
    "    * Logistic Regression\n",
    "    * Support Vector Machines\n",
    "* Nonlinear models\n",
    "    * K-nearest Neighbors (KNN)\n",
    "    * Kernel Support Vector Machines (SVM)\n",
    "    * Naïve Bayes\n",
    "    * Decision Tree Classification\n",
    "    * Random Forest Classification\n",
    "\n",
    "In order to evaluate the quality of our model we will be using the following metrics:\n",
    "\n",
    "* Accuracy: Correct Predictions / Total predictions\n",
    "* Precision: True Positive / (True Positive + False Positive)\n",
    "* Recall: True Positive / (True Positive + False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "def scores(y, y_pred):\n",
    "    precision = precision_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    print('-----------------')\n",
    "    print('Precision')\n",
    "    print(precision)\n",
    "    print('-----------------')\n",
    "    print('Accuracy')\n",
    "    print(accuracy)\n",
    "    print('-----------------')\n",
    "    print('Recall')\n",
    "    print(recall)\n",
    "    cnf_mat = confusion_matrix(y,y_pred)\n",
    "    print('-----------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(cnf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Precision\n",
      "0.8598057025511413\n",
      "-----------------\n",
      "Accuracy\n",
      "0.8634\n",
      "-----------------\n",
      "Recall\n",
      "0.8690723295545266\n",
      "-----------------\n",
      "Confusion Matrix\n",
      "[[10699  1775]\n",
      " [ 1640 10886]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = LogisticRegression(C=0.7)\n",
    "clf.fit(x_train_std, y_train)\n",
    "y_pred = clf.predict(x_test_std)\n",
    "scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Precision\n",
      "0.7688061708300898\n",
      "-----------------\n",
      "Accuracy\n",
      "0.80284\n",
      "-----------------\n",
      "Recall\n",
      "0.8673159827558677\n",
      "-----------------\n",
      "Confusion Matrix\n",
      "[[ 9207  3267]\n",
      " [ 1662 10864]]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=3,n_estimators=500, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "scores(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
