{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Figuring out Natural Language Processing\n",
    "As I have never worked on NLP before, the purpose of this notebook was to play arround with a dataset and try to figure out a bunch of stuff on the subject.\n",
    "Here we will be working on the IMDB dataset which provides 50k movies text reviews and their corresponding sentiment  \"Positive\" or \"Negative\".\n",
    "\n",
    "Our job will be to find a way to learn some features that can predict the sentiment based on a textual review. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "We will be getting the data from my google drive. I have downloaded those data from Kaggle https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "orig_url='https://drive.google.com/file/d/1Tl9AMNkExM5mFw3xDuIeZ1RiDIEu4Oci/view?usp=sharing'\n",
    "file_id = orig_url.split('/')[-2]\n",
    "dwn_url='https://drive.google.com/uc?export=download&id=' + file_id\n",
    "url = requests.get(dwn_url).text\n",
    "csv_raw = StringIO(url)\n",
    "df_dwnld = pd.read_csv(csv_raw)\n",
    "df = df_dwnld.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Now that we have the data, and displayed some of those data, we know that there is cleaning to be made. \n",
    "\n",
    "For this analysis, I will assume that numbers are meaningless and that we need only words to predict the sentiment. \n",
    "Therefore, we will get rid of : \n",
    "* numbers,\n",
    "* html tags,\n",
    "* uppercases,\n",
    "* any special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one of the other reviewers has mentioned that after watching just oz episode youll be hooked they are right as this is exactly what happened with methe first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordit is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awayi would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode ever saw struck me as so nasty it was surreal couldnt say was ready for it but as watched more developed taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove numbers\n",
    "df['clean_review'] = df['review'].str.replace('\\d+', '')\n",
    "# Remove any <> and everything inside\n",
    "df['clean_review'] = df['clean_review'].str.replace('<[^<]+?>', '')\n",
    "# Remove anything that is not alphanumeric\n",
    "df['clean_review'] = df['clean_review'].str.replace(r'[^A-Za-z0-9 ]+', '')\n",
    "# Remove any uppercase character\n",
    "df['clean_review'] = df['clean_review'].str.lower()\n",
    "# Remove any one character words\n",
    "df['clean_review'] = df['clean_review'].str.replace(r'\\b\\w\\b', '')\n",
    "# Remove multiple spaces \n",
    "df['clean_review'] = df['clean_review'].str.replace(r'\\s+', ' ')\n",
    "# Strip data\n",
    "df['clean_review'] = df['clean_review'].str.strip()\n",
    "\n",
    "df['clean_review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What direction ? \n",
    "Now, we have a text that seems to be way more clean. \n",
    "\n",
    "Obviously, we will have to create some features out of all these words in order to extract the sentiment. \n",
    "\n",
    "What I mean by that is that we need to create a standardized framework in which any review could fit. The problem with those textual input is that they are of random sizes, and any model that we might create will need inputs of pre-defined sizes.\n",
    "\n",
    "What we will be using here is some kind of one-hot-encoding technic. The concept is simple, you take a categorical variable and transform it in vector space. ie: \n",
    "\n",
    "| category |\n",
    "|---|\n",
    "| A |\n",
    "| B |\n",
    "| C | \n",
    "\n",
    "| A | B | C |\n",
    "|---|---|---|\n",
    "| 1 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 0 | 0 | 1 |\n",
    "\n",
    "-----------\n",
    "\n",
    "Here, the columns will be some relevants words that we believe to have predictive power.\n",
    "\n",
    "In order to find them, let's play arround with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns 'words' will contains a list of all the words in the 'clean' column\n",
    "df['words_'] = df.clean_review.str.split('\\s+')\n",
    "df.words_[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Now we will identify ALL the words that have been used and count how many time they have been used.\n",
    "\n",
    "It is important to split your data in training and testing set. Therefore we will do it right now by spliting the dataset in half and we will be doing ou analysis only on the first half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>210064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>266297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>288080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>319406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>650762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count\n",
       "is   210064\n",
       "to   266297\n",
       "of   288080\n",
       "and  319406\n",
       "the  650762"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we define the lenght of our training set. which will be half of the dataset.\n",
    "total = x.shape[0]\n",
    "n = total // 2\n",
    "\n",
    "dict_count = {}\n",
    "data = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "# We will loop only on the first n reviews\n",
    "for d in data[:n]:\n",
    "    for w in d[3]:\n",
    "        if not w in dict_count:\n",
    "            dict_count[w] = 1\n",
    "        else:\n",
    "            dict_count[w] +=1\n",
    "\n",
    "df_count = pd.DataFrame(dict_count, index=['Count']).T.sort_values('Count')\n",
    "df_count.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words problem\n",
    "And here we are, the famous stop words problems. \n",
    "This was indeed pretty well expected, the words that are the most common will be completely useless in our case. \n",
    "\n",
    "A good practice is to get rid of them.\n",
    "The sklearn library has a english stop word frozen set, we will use it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>14378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>17317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>19555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>37345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>41962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count\n",
       "good   14378\n",
       "just   17317\n",
       "like   19555\n",
       "film   37345\n",
       "movie  41962"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "df_count = df_count.loc[~df_count.index.isin(stop_words.ENGLISH_STOP_WORDS)]\n",
    "df_count.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next step\n",
    "Now for each of these words, I will add a column to the DataFrame and I want to count how many time each of them appear in each review. This is where we use \"some kind\" of one-hot-encoding technics as we will not populate with 1 or 0 but with a number of occurence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_review</th>\n",
       "      <th>_predict</th>\n",
       "      <th>clean_review</th>\n",
       "      <th>words_</th>\n",
       "      <th>memories</th>\n",
       "      <th>mike</th>\n",
       "      <th>locations</th>\n",
       "      <th>learned</th>\n",
       "      <th>lovers</th>\n",
       "      <th>noticed</th>\n",
       "      <th>...</th>\n",
       "      <th>lowbudget</th>\n",
       "      <th>occasionally</th>\n",
       "      <th>wind</th>\n",
       "      <th>fights</th>\n",
       "      <th>cars</th>\n",
       "      <th>officer</th>\n",
       "      <th>leader</th>\n",
       "      <th>ordinary</th>\n",
       "      <th>boat</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>[one, of, the, other, reviewers, has, mentione...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production the filming techni...</td>\n",
       "      <td>[wonderful, little, production, the, filming, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought this was wonderful way to spend time o...</td>\n",
       "      <td>[thought, this, was, wonderful, way, to, spend...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres family where little boy jake ...</td>\n",
       "      <td>[basically, theres, family, where, little, boy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love in the time of money is vi...</td>\n",
       "      <td>[petter, matteis, love, in, the, time, of, mon...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             _review  _predict  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                        clean_review  \\\n",
       "0  one of the other reviewers has mentioned that ...   \n",
       "1  wonderful little production the filming techni...   \n",
       "2  thought this was wonderful way to spend time o...   \n",
       "3  basically theres family where little boy jake ...   \n",
       "4  petter matteis love in the time of money is vi...   \n",
       "\n",
       "                                              words_  memories  mike  \\\n",
       "0  [one, of, the, other, reviewers, has, mentione...         0     0   \n",
       "1  [wonderful, little, production, the, filming, ...         0     0   \n",
       "2  [thought, this, was, wonderful, way, to, spend...         0     0   \n",
       "3  [basically, theres, family, where, little, boy...         0     0   \n",
       "4  [petter, matteis, love, in, the, time, of, mon...         0     0   \n",
       "\n",
       "   locations  learned  lovers  noticed  ...  lowbudget  occasionally  wind  \\\n",
       "0          0        0       0        0  ...          0             0     0   \n",
       "1          0        0       0        0  ...          0             0     0   \n",
       "2          0        0       0        0  ...          0             0     0   \n",
       "3          0        0       0        0  ...          0             0     0   \n",
       "4          0        0       0        0  ...          0             0     0   \n",
       "\n",
       "   fights  cars  officer  leader  ordinary  boat  review  \n",
       "0       0     0        0       0         0     0       1  \n",
       "1       0     0        0       0         0     0       0  \n",
       "2       0     0        0       0         0     0       0  \n",
       "3       0     0        0       0         0     0       0  \n",
       "4       0     0        0       0         0     0       0  \n",
       "\n",
       "[5 rows x 1532 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words = df_count.tail(1500).index.tolist()\n",
    "\n",
    "# Rename the columns as their name might appear in the list of words\n",
    "df = df.rename({\n",
    "    \"sentiment\": '_predict',\n",
    "    \"review\": \"_review\"\n",
    "}, axis=1)\n",
    "\n",
    "for word in top_words:\n",
    "    df[word] = df.clean_review.str.count(word)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where are the interesting stuff ??\n",
    "Alright, now that we have counted everything, why don't we group our data by sentiment, positive or negative, and see if any words appears way more often in a group and not in the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wonderfully   -0.866038\n",
       "beautifully   -0.843915\n",
       "superb        -0.821084\n",
       "wonderful     -0.805434\n",
       "touching      -0.805195\n",
       "                 ...   \n",
       "poorly         8.388060\n",
       "laughable      8.653846\n",
       "waste          8.919271\n",
       "redeeming      9.017857\n",
       "worst          9.961883\n",
       "Name: diff_, Length: 1500, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df[['_predict',*top_words]].groupby('_predict').mean().T\n",
    "result['diff_'] = (result.negative / result.positive) -1\n",
    "result.diff_.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That is interesting\n",
    "So here we are, words such as beautiful and wonderful are way more often used in a positive review than in a negative review. And words like worst, and awful are more often used in a negative review. \n",
    "\n",
    "Again, I believe those results are pretty obvious, that is just common sense. However it still took us less time than coming up with 1500 words by ourself. \n",
    "\n",
    "By looking at the data so far, I'm assuming that there should be some predictive power in our variable. Let's prepare our data and try to fit a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = df[['_predict', *top_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "x = predict_df.drop('_predict', axis=1)\n",
    "y = predict_df['_predict']\n",
    "y = y.replace({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "n_test = total - n\n",
    "x_train = x.iloc[:n,:].values\n",
    "y_train = y.iloc[:n].values\n",
    "\n",
    "x_test =  x.iloc[n:,:].values\n",
    "y_test =  y.iloc[n:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the data\n",
    "Some learning models require the data to be normalize in some way. \n",
    "Here we will just standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
    "x_test_std = (x_test - x_train.mean(axis=0)) / x_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn\n",
    "It is time to create our model. \n",
    "\n",
    "This problem is a classification problem. Therefore we can choose among the following learning technics :\n",
    "\n",
    "* Linear Models\n",
    "    * Logistic Regression\n",
    "    * Support Vector Machines\n",
    "* Nonlinear models\n",
    "    * K-nearest Neighbors (KNN)\n",
    "    * Kernel Support Vector Machines (SVM)\n",
    "    * Naïve Bayes\n",
    "    * Decision Tree Classification\n",
    "    * Random Forest Classification\n",
    "\n",
    "For this type of classification problem, I usually run a simple logistic regression as well as a Random forest classification. \n",
    "Now, we will just look into the logistic regression\n",
    "\n",
    "In order to evaluate the quality of our model we will be using the following metrics:\n",
    "\n",
    "* Accuracy: Correct Predictions / Total predictions\n",
    "* Precision: True Positive / (True Positive + False Positive)\n",
    "* Recall: True Positive / (True Positive + False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "def scores(y, y_pred):\n",
    "    precision = precision_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    print('-----------------')\n",
    "    print('Precision')\n",
    "    print(precision)\n",
    "    print('-----------------')\n",
    "    print('Accuracy')\n",
    "    print(accuracy)\n",
    "    print('-----------------')\n",
    "    print('Recall')\n",
    "    print(recall)\n",
    "    cnf_mat = confusion_matrix(y,y_pred)\n",
    "    print('-----------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(cnf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "\n",
    "This regression is used when the variable to predict is categorical (1 or 0). \n",
    "\n",
    "For our convenience, we will be using the LogisticRegressionCV class from scikit-learn which is doing the Cross-validation for us.\n",
    "What it does is playing with a list of lambda values which defines the strenght of the penalty term and a list of l1_ratios which makes our penalty term closer to either L1 or L2 when using the elasticnet penalty term.\n",
    "\n",
    "As the default solver only supports the l2 penalty term, we will be fine with that and our CV will decide only which lambda fits better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Precision\n",
      "0.8644014718546935\n",
      "-----------------\n",
      "Accuracy\n",
      "0.87132\n",
      "-----------------\n",
      "Recall\n",
      "0.8814465910905317\n",
      "-----------------\n",
      "Confusion Matrix\n",
      "[[10742  1732]\n",
      " [ 1485 11041]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = LogisticRegressionCV()\n",
    "clf.fit(x_train_std, y_train)\n",
    "y_pred = clf.predict(x_test_std)\n",
    "scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are pretty good as we have not been doing any extensive feature engineering here.\n",
    "On the back of those results, we are now able to read some review that the model was not able to predict and try to identify a pattern that our model can't handle. This would help us improving our feature engineering process. \n",
    "\n",
    "However, for the purpose of this notebook, I will just stop here. Feel free to play with the data and find better alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df.clean_review.iloc[:n].to_frame()\n",
    "output.loc[:,'prediction'] = (y_test - y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this show was an amazing fresh innovative idea in the when it first aired the first or years were brilliant but things dropped off after that by the show was not really funny anymore and its continued its decline further to the complete waste of time it is todayits truly disgraceful how far this show has fallen the writing is painfully bad the performances are almost as bad if not for the mildly entertaining respite of the guesthosts this show probably wouldnt still be on the air find it so hard to believe that the same creator that handselected the original cast also chose the band of hacks that followed how can one recognize such brilliance and then see fit to replace it with such mediocrity felt must give stars out of respect for the original cast that made this show such huge success as it is now the show is just awful cant believe its still on the air'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrong prediction\n",
    "output.query('prediction==1').iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'petter matteis love in the time of money is visually stunning film to watch mr mattei offers us vivid portrait about human relations this is movie that seems to be telling us what money power and success do to people in the different situations we encounter this being variation on the arthur schnitzlers play about the same theme the director transfers the action to the present time new york where all these different characters meet and connect each one is connected in one way or another to the next person but no one seems to know the previous point of contact stylishly the film has sophisticated luxurious look we are taken to see how these people live and the world they live in their own habitatthe only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits big city is not exactly the best place in which human relations find sincere fulfillment as one discerns is the case with most of the people we encounterthe acting is good under mr matteis direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier and the rest of the talented cast make these characters come alivewe wish mr mattei good luck and await anxiously for his next work'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrong prediction\n",
    "output.query('prediction==-1').iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'petter matteis love in the time of money is visually stunning film to watch mr mattei offers us vivid portrait about human relations this is movie that seems to be telling us what money power and success do to people in the different situations we encounter this being variation on the arthur schnitzlers play about the same theme the director transfers the action to the present time new york where all these different characters meet and connect each one is connected in one way or another to the next person but no one seems to know the previous point of contact stylishly the film has sophisticated luxurious look we are taken to see how these people live and the world they live in their own habitatthe only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits big city is not exactly the best place in which human relations find sincere fulfillment as one discerns is the case with most of the people we encounterthe acting is good under mr matteis direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier and the rest of the talented cast make these characters come alivewe wish mr mattei good luck and await anxiously for his next work'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good prediction\n",
    "output.query('prediction==-1').iloc[0,0]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
